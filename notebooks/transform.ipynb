{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(html_content):\n",
    "    # get the html text into a dataframe\n",
    "    df = html_content_to_df(html_content)\n",
    "\n",
    "    # clean our data within the dataframe\n",
    "    df_clean = clean_data_in_df(df)\n",
    "\n",
    "    # generate our calendar of weeks\n",
    "    df_week_data = generate_week_data()\n",
    "\n",
    "    # merge our dataframe with the week metadata\n",
    "    df_final = merge_df_with_week_metadata(df_clean,df_week_data)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_week_data():\n",
    "    tdelta_begin_wk = timedelta(days = -6)\n",
    "    tdelta_next_week_end_date = timedelta(days = 7)\n",
    "\n",
    "    season_weeks = [\n",
    "        ['2017-18',datetime(2017,5, 28),0,53],\n",
    "        ['2018-19',datetime(2018,6, 3),0,52],\n",
    "        ['2019-20',datetime(2019,6, 2),0,41],\n",
    "        ['2020-21',datetime(2020,6, 1),-1,52],\n",
    "        ['2021-22',datetime(2021,5, 30),10,52],\n",
    "        ['2022-23',datetime(2022,5, 29),0,52]\n",
    "    ]\n",
    "\n",
    "    week_df_columns = ['season','week_num','week_start_date','week_end_date']\n",
    "    week_data = []\n",
    "\n",
    "    for row in season_weeks:\n",
    "        season = row[0]\n",
    "        season_start_date_we = row[1]\n",
    "        num_weeks_offset = row[2]\n",
    "        week_end_date = season_start_date_we + timedelta(days=7*num_weeks_offset)\n",
    "        num_weeks = row[3]\n",
    "\n",
    "        if not(season == '2020-21'): #exclude the 2020-21 season because of Pandemic\n",
    "            \n",
    "            for i in range(num_weeks_offset+1,num_weeks+1):\n",
    "                week_start_date = week_end_date + tdelta_begin_wk\n",
    "                \n",
    "                week_data.append([season,i,week_start_date,week_end_date])\n",
    "    \n",
    "                week_end_date += tdelta_next_week_end_date\n",
    "            \n",
    "    df_week_data = pd.DataFrame(week_data,columns=week_df_columns)\n",
    "\n",
    "    return df_week_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_content_to_df(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html5lib') # oddly, html.parser was not finding the header row tr tag of the table\n",
    "\n",
    "    data = []\n",
    "\n",
    "    if soup: # make sure there's content to process\n",
    "        # get the report week ending date\n",
    "        report_we_date = soup.find(id='vault-search-results-sort-select').find('option', selected=True).text\n",
    "        report_we_date_dt = datetime.strptime(report_we_date,'%Y-%m-%d')\n",
    "\n",
    "        # get the week number\n",
    "        weeknum = soup.find('div',class_='week-count').find('span').text\n",
    "\n",
    "        # find the table element on the webpage\n",
    "        table = soup.find('div', class_='vault-grosses-result').find('table')\n",
    "\n",
    "        # find all of the rows within the html table\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        # iterate over all of the table rows including within the table header\n",
    "        for row in rows:\n",
    "\n",
    "            row_data = []\n",
    "            cells = row.find_all(['th', 'td'])\n",
    "            \n",
    "            # iterate over all of the cells within the row and fetch the respective cell value\n",
    "            for cell in cells:\n",
    "                # if it is a column header\n",
    "                if cell.name=='th':\n",
    "                    row_data.append(cell.a.text.strip())\n",
    "\n",
    "                    if(cell.find('span',class_='subtext')):\n",
    "                        row_data.append(cell.find('span',class_='subtext').text.strip())\n",
    "                    else:\n",
    "                        row_data.append(None)\n",
    "                # it is not a column header\n",
    "                else:\n",
    "                    if(cell.find('span',class_='data-value')):\n",
    "                        row_data.append(cell.find('span',class_='data-value').text.strip())\n",
    "                    else:\n",
    "                        row_data.append(None)\n",
    "\n",
    "                    if(cell.find('span',class_='subtext')):\n",
    "                        row_data.append(cell.find('span',class_='subtext').text.strip())\n",
    "                    else:\n",
    "                        row_data.append(None)\n",
    "            \n",
    "            # append the row data\n",
    "            data.append(row_data)\n",
    "\n",
    "        # create a dataframe from the processed data\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "        # add an additional column in the dataframe for the report week ending date\n",
    "        df['week_end_date'] = report_we_date_dt\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(\"there is no soup\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_in_df(df_to_clean):\n",
    "    df = df_to_clean.copy()\n",
    "    \n",
    "    # drop NA columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # add a column name for the Venue\n",
    "    df.columns.values[1] = 'venue_name'\n",
    "\n",
    "    # rename columns to what they are in the db table\n",
    "    df.rename(columns={\n",
    "        'Show' : 'show_name',\n",
    "        'This Week Gross' : 'tw_gross',\n",
    "        'Potential Gross' : 'potential_gross',\n",
    "        'Diff $' : 'diff_tw_lw_gross',\n",
    "        'Avg Ticket' : 'avg_ticket_price',\n",
    "        'Top Ticket' : 'max_ticket_price',\n",
    "        'Seats Sold' : 'seats_sold',\n",
    "        'Seats in Theatre' : 'seats_in_theater',\n",
    "        'Perfs' : 'performances',\n",
    "        'Previews' : 'preview_performances',\n",
    "        f'% Cap' : 'pct_capacity',\n",
    "        f'Diff % cap' : 'diff_tw_lw_pct_capacity'\n",
    "    },inplace=True)\n",
    "\n",
    "    # convert the currency strings to floats\n",
    "    def convert_currency_to_decimal(value):\n",
    "        # Check if the value is a string and contains a dollar sign\n",
    "        if isinstance(value, str) and '$' in value:\n",
    "            # Remove dollar sign and comma, and convert to float\n",
    "            return Decimal(value.replace(',', '').replace('$', ''))\n",
    "        return value\n",
    "\n",
    "    currency_columns_to_convert = ['This Week Gross','Potential Gross','Diff $','Avg Ticket','Top Ticket']\n",
    "    df[currency_columns_to_convert] = df[currency_columns_to_convert].applymap(convert_currency_to_decimal)\n",
    "\n",
    "    # convert string numbers to integers\n",
    "    def convert_str_numbers_to_numbers(value):\n",
    "        converted_value = value\n",
    "        if isinstance(value, str):\n",
    "            if ',' in value:\n",
    "                converted_value = converted_value.replace(',','')\n",
    "            return int(converted_value)\n",
    "        return converted_value\n",
    "\n",
    "    number_columns_to_convert = ['Seats Sold','Seats in Theatre','Perfs','Previews']\n",
    "    df[number_columns_to_convert] = df[number_columns_to_convert].applymap(convert_str_numbers_to_numbers)\n",
    "\n",
    "    # convert percent values to floats\n",
    "    def convert_pct_to_float(value):\n",
    "        if isinstance(value, str) and '%' in value:\n",
    "            return float(value.replace('%', '')) / 100\n",
    "        return value\n",
    "\n",
    "    pct_columns_to_convert = ['pct_capacity','diff_tw_lw_pct_capacity']\n",
    "    df[pct_columns_to_convert] = df[pct_columns_to_convert].applymap(convert_pct_to_float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_with_week_metadata(df,df_week_data):\n",
    "    df_merged = pd.merge(df,df_week_data,how='left',on='week_end_date')\n",
    "\n",
    "    df_final = df_merged[[\n",
    "        'show_name',\n",
    "        'venue_name',\n",
    "        'season',\n",
    "        'week_num',\n",
    "        'week_start_date',\n",
    "        'week_end_date',\n",
    "        'tw_gross',\n",
    "        'potential_gross',\n",
    "        'diff_tw_lw_gross',\n",
    "        'avg_ticket_price',\n",
    "        'max_ticket_price',\n",
    "        'seats_sold\tseats_in_theater',\n",
    "        'performances',\n",
    "        'preview_performances',\n",
    "        'pct_capacity',\n",
    "        'diff_tw_lw_pct_capacity'\n",
    "    ]]\n",
    "\n",
    "    return df_final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
